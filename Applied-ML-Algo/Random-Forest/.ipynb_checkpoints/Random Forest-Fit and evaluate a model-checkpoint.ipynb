{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmuntaner\\Anaconda3\\envs\\ML-env\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "tr_features = pd.read_csv('../data/train_features.csv')\n",
    "tr_labels = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "This image provides a quick reminder of what the two hyperparameters are that i'll be tuning.\n",
    "\n",
    "Number of estimators simply represents how many individua decision trees to build.\n",
    "\n",
    "Max_depth dictates how deep each of those decision trees can go. \n",
    "![RF](../img/rf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "0.781 (+/-0.109) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.792 (+/-0.121) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.802 (+/-0.103) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.817 (+/-0.122) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.83 (+/-0.1) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.824 (+/-0.108) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.82 (+/-0.08) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.824 (+/-0.067) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.822 (+/-0.072) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.8 (+/-0.066) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.811 (+/-0.018) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.811 (+/-0.029) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.803 (+/-0.039) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.815 (+/-0.036) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.811 (+/-0.029) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.787 (+/-0.022) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.811 (+/-0.029) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.809 (+/-0.034) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# defining my hyperparameter dictionary:\n",
    "# for n_estimators i will test out building 5, 50, 250 decision trees.\n",
    "# for max_depth i will test out 2, 4, 8, 16, 32, and none. this will control how deep each tree in n_estimators can go.\n",
    "\n",
    "# the None setting will let the tree go as deep as it wants until it reaches some level-\n",
    "# of training at a tolerance thats defined within Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "Before i dig into the results, i want to call out that with Random Forest, even if i ran this exact cell again, on the same exact training set, i would get different results. \n",
    "\n",
    "Thats because each time you run Random Forest, it is randomly sampling rows and columns internally, to build each individual decision tree. \n",
    "\n",
    "Looking at these results, the best accuracy is produced by a model with 50 estimators and a max_depth of 4. This generate an overall accuracy of 83%. \n",
    "\n",
    "This is the best cross validation performance that i have seen so far. \n",
    "\n",
    "Two things that i want to call out quickly: it's clear that 5 estimators is not quite enough, if i look through every combination, the worst one is usually the one with only 5 estimators. \n",
    "\n",
    "I can also see that throughout the combinations, the ones that have a max_depth of 4 do quite well. Same with a depth of 8.\n",
    "\n",
    "It really starts to fall off after the max_depth of eight, which indicates that they might be over-fitting just a little bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/RF_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, '../data/RF_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
